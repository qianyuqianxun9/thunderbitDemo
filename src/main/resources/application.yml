spring:
  application:
    name: crawler-service

  # DataSource Configuration
  datasource:
    url: jdbc:mysql://localhost:3306/crawler_db?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai
    username: root
    password: root
    driver-class-name: com.mysql.cj.jdbc.Driver
    hikari:
      maximum-pool-size: 10
      minimum-idle: 5
      connection-timeout: 30000

  # JPA Configuration
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQLDialect
        format_sql: true

  # Redis Configuration (for live status cache)
  data:
    redis:
      host: localhost
      port: 6379
      password:
      database: 0
      timeout: 3000ms
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 0

  # Kafka Configuration
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 3
      properties:
        max.in.flight.requests.per.connection: 1
    consumer:
      group-id: crawler-worker-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
      enable-auto-commit: false
      properties:
        max.poll.records: 10

# Server Configuration
server:
  port: 8080
  servlet:
    context-path: /

# Logging Configuration
logging:
  level:
    root: INFO
    com.example.crawler: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"

# Crawler Worker Resource Configuration
crawler:
  worker:
    total-instances: 1
    max-threads-per-instance: 10
  
  user-resource-limit:
    time-window-seconds: 3600  # 1小时
    max-threads-per-window: 50  # 每个用户在时间窗口内最大线程数
    max-jobs-per-window: 10     # 每个用户在时间窗口内最大任务数

